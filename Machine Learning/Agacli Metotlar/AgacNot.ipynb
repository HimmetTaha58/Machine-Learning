{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temelde benim anladığım şu eğer tam bir sonuç ve doğruluk istiyorsan random forest kullanacaksın benim modelim çalışsın biraz da performanslı olsun diyorsan decision tree kullanmalısın \n",
    "Dikkat Etmen Gerekenler:\n",
    "\n",
    "Decision Treede overfitting riski var\n",
    "\n",
    "Random Forestta da Decision treede de ama özellikle Random Forest da   n_estimators sayısı bootstrap ve oob tarzı parametreler için GridSearch ile hiper parametre kontrolü çok çok önemli onları bulunca zaten en iyi modelimiz oluşmuş oluyor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Decision Trees (Karar Ağaçları)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanım:\n",
    "\n",
    "Decision Trees, hem sınıflandırma (classification) hem de regresyon problemleri için kullanılan, veriyi özelliklere dayalı olarak ardışık sorularla bölen (split) bir supervised learning algoritmasıdır. Ağaç yapısı, kök düğüm (root node), iç düğümler (internal nodes) ve yaprak düğümlerden (leaf nodes) oluşur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ağacın Büyümesi ve Durdurma Kriterleri\n",
    "\n",
    "Pre-pruning (Erken Durdurma):\n",
    "Hiperparametrelerle ağacın büyümesini sınırlama:\n",
    "\n",
    "max_depth: Ağacın maksimum derinliği.\n",
    "\n",
    "min_samples_split: Bir düğümün split edilebilmesi için gereken minimum örnek sayısı.\n",
    "\n",
    "min_samples_leaf: Bir yaprak düğümde olması gereken minimum örnek sayısı.\n",
    "\n",
    "max_features: Split sırasında değerlendirilecek maksimum özellik sayısı.\n",
    "\n",
    "Post-pruning:\n",
    "Ağaç tam büyüdükten sonra gereksiz dalları budama (örneğin, CCP - Cost Complexity Pruning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avantajlar\n",
    "\n",
    "Yorumlanabilirlik (if-else kuralları şeklinde görselleştirilebilir).\n",
    "\n",
    "Ölçeklendirme gerektirmez (normalizasyon/min-max gibi).\n",
    "\n",
    "Hem kategorik hem sayısal verilerle çalışabilir (kategorikler için genellikle one-hot encoding gerekir).\n",
    "\n",
    "Non-lineer ilişkileri ve feature interaction’ları yakalar.\n",
    "\n",
    "\n",
    "\n",
    "Dezavantajlar\n",
    "\n",
    "Yüksek varyans: Küçük veri değişiklikleri ağaç yapısını tamamen değiştirebilir.\n",
    "\n",
    "Overfitting: Derin ağaçlar eğitim verisine çok iyi uyar, test performansı düşer.\n",
    "\n",
    "Bias: Çok seviyeli kategorik özellikler (high cardinality) veya baskın özellikler ağacı yanıltabilir.\n",
    "\n",
    "Regresyonda sınırlı performans: Sürekli hedef değişkenlerde basamaklı tahminler yapar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Random Forests**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanım:\n",
    "Random Forests, çok sayıda Decision Tree’yi birleştiren (ensemble) bir yöntemdir. Bagging (Bootstrap Aggregating) ve feature randomness kullanarak ağaçların çeşitliliğini artırır, böylece varyansı azaltır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temel Kavramlar\n",
    "\n",
    "\n",
    "Bagging (Bootstrap Aggregating)\n",
    "\n",
    "Her ağaç, eğitim verisinden yerine koymalı örnekleme (bootstrap) ile oluşturulan alt kümelerle eğitilir.\n",
    "Tahminler ağaçların ortalaması (regresyon) veya çoğunluk oyu (sınıflandırma) ile yapılır.\n",
    "Out-of-Bag (OOB) Error: Her ağaç için bootstrap’e girmeyen örneklerin validasyon hatası. Modelin performansını cross-validation’a gerek kalmadan tahmin eder.\n",
    "\n",
    "Feature Randomness\n",
    "\n",
    "Her split’te rastgele bir alt özellik kümesi (max_features) kullanılır.\n",
    "Amaç: Ağaçlar arası korelasyonu azaltmak (örneğin, max_features=sqrt(n_features)).\n",
    "Dikkat: max_features çok düşükse underfitting, çok yüksekse ağaçlar benzer olur.\n",
    "\n",
    "\n",
    "\n",
    "Hiperparametreler\n",
    "\n",
    "n_estimators: Ağaç sayısı (genelde 100-1000 arası, daha fazlası performansı artırır ancak hesaplama maliyetli).\n",
    "max_depth: Ağaçların maksimum derinliği (derin ağaçlar overfit’e yol açabilir).\n",
    "min_samples_split, min_samples_leaf: Ağaçların karmaşıklığını kontrol eder.\n",
    "bootstrap: Bootstrap örnekleme yapılıp yapılmayacağı (varsayılan=True).\n",
    "oob_score: OOB error’u hesaplama (varsayılan=False)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avantajlar\n",
    "\n",
    "Tek bir ağaca göre daha düşük varyans ve daha iyi genelleme.\n",
    "Overfitting’e daha dirençli.\n",
    "Feature importance hesaplanabilir.\n",
    "Paralelize edilebilir (ağaçlar bağımsız olduğu için).\n",
    "\n",
    "Dezavantajlar\n",
    "\n",
    "Yorumlanabilirlik düşüktür (tek bir ağaçtan daha karmaşık).\n",
    "Eğitim süresi ve bellek kullanımı yüksek olabilir.\n",
    "Çok yüksek boyutlu verilerde (örneğin, metin verisi) verimsiz olabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basitlik vs. Performans: Hızlı prototipleme için Decision Tree, yüksek performans için Random Forest.\n",
    "\n",
    "Boyut Etkisi: Random Forest, yüksek boyutlu veride max_features ile kontrol edilmeli.\n",
    "\n",
    "Deploy Etme: Random Forest’lerin model boyutu büyük olabilir; edge computing’de dikkat.\n",
    "\n",
    "Açıklanabilirlik: LIME veya SHAP ile model çıktıları açıklanabilir."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
