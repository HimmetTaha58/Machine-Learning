{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu nota bakıp anlamazsan git direk kodları oku orada da açıklamalar var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada kısaca nelerin önemli olduğunu ve neden yaptığımızı anlatacağım\n",
    " Önemli olan şey n_estimators (kullanılacak ağaç sayısı) nı doğru belirleyebilmek ve bazı parametreler n_estimators ve parametreleri GridSearchCV ile bizim için en iyi olan parametreleri bulabiliyoruz aşşağıda kod satırı: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = [9, 64, 128, 200] # Farazi olarak girdik Ağaç sayılarımız\n",
    "max_feat = [1,2,3,4] # Ağaçta her sağa sola giden bölünemede kullanılacak veri sayısı hani örneğin 3 veriye aynı anda bakıp sağa ya da sola gidecek\n",
    "bootstrap_sec = [True, False]\n",
    "# Bootstrap False ise her ağaç için bütün veriler kullanılır , True ise 3429 tanenin içinden bir kaç tanesini seçip onları kullanmak isteyecek\n",
    "oob = [True, False]\n",
    "# Bu sadece bootstrap True ise yani veri seçilecekse çalışıyor Bunun görevi ise 3429 tane veriden 30 tanesini seçtim boostrap kısmında bu yeni farklı bir veri ekleyeyimmi bir yanlılık katalımmı diye var (out of bag) anlamı "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"n_estimators\" : n_est,\n",
    "    \"max_features\" : max_feat,\n",
    "    \"bootstrap\"    : bootstrap_sec,\n",
    "    \"oob_score\"    : oob\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest  = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burada yaptığı 9 ağaç için her bir parametreyi deniyor sonra 64 için de deniyor hepsi için bunu yapıyor\n",
    "grid = GridSearchCV(\n",
    "    random_forest, \n",
    "    parameters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Yukarıda biz kendimiz bazı estimaors sayıları verdik ve bunlardan hangisinin en uygun olduğunu GridSearchCV algoritmasına seçtirdik yukarıda yazdığımız parametrelere ve n_estimator(ağaç sayısı) na tek tek deneyerek baktı ve bize en iyisini bulup onu kullandırdı\n",
    "\n",
    " !#! Burada önemli olan bir diğer kısım ise en iyi n_esitmators(ağaç sayısı) nı bulmak biz yukarıdaki kodlarda GridSearchCV ile en iyi parametreleri bulmuş olabiliriz ama belki de bizim modelimiz için en iyi n_estimators değeri yazdıklarımızdan birisi değildir (genellikle) o yüzden aşşağıda en iyi ağaç sayısını bulacağız bu ağaç sayısını bulurken GridSearchCV ile yukarıda bulduğumuz parametreleri aşşağıda bulurken içine yazarak modelimizi daha performanslı ve kolay hale getiriyoruz \n",
    " \n",
    " En iyi Ağaç Sayısı:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hata_payi = [] # Hata payi\n",
    "yanlis_secim = [] # Kaç pilavin yanlış seçildiği\n",
    "\n",
    "for n in range(1, 130):\n",
    "    rand_forest_class = RandomForestClassifier(n_estimators=n, bootstrap= True , oob_score = False, max_features=1)\n",
    "# Yukarıda best_params lar grid searchte gelmişti onları ekledik boostrap oob ve max_features için\n",
    "    \n",
    "    rand_forest_class.fit(X_train, y_train)\n",
    "    pirinc_pred = rand_forest_class.predict(X_test)\n",
    "\n",
    "    error = 1 - accuracy_score(pirinc_pred, y_test)\n",
    "\n",
    "    sample = y_test.to_numpy()\n",
    "    # y_testi numpy türüne çevirdik\n",
    "    sample = sample.reshape(1, -1)[0]\n",
    "    # Bu sampleı böyle yazmalıyız Tek satırda yazmak için\n",
    "\n",
    "    # Aşşağıda hatalı verileri bulabilmek için sample muhabbeti var\n",
    "    n_missed = np.sum(pirinc_pred != sample)\n",
    "    hata_payi.append(error)\n",
    "    yanlis_secim.append(n_missed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
